{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "14a05cbb",
   "metadata": {},
   "source": [
    "## Regression Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30bbeead",
   "metadata": {},
   "source": [
    "We can technically stop at our classification task, as our imaginary client might be satisfied in knowing whether their campaign will be successful or not given the required inputs. However, what can we do more? Perhaps, we can help them to estimate how much are they likely to raise with the given variables. We can attempt to predict the probability of whether they are likely to success and use this as an input to finally output how much are they likely to raise as a result. To do this, first, we need to find the right model to predict the probability. Next, we will need to find out whether there is a correlation between this probability and how much they are likely to raise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0899d6b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from sklearn.model_selection import train_test_split\n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59f5da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Processing\n",
    "df = pd.read_csv(\"variables.csv\")\n",
    "df = df.drop(['Unnamed: 0'],axis=1)\n",
    "df_x = df[['Total_Days','currency','category','month_launch']]\n",
    "df_y = df[['amount_raised_usd_boxcox','state']]\n",
    "df_x_onehot = df_x.copy()\n",
    "\n",
    "for c in df_x_onehot.columns:\n",
    "    df_x_onehot[c] = df_x_onehot[c].astype('object') # changing to object type for onehot processsing\n",
    "    \n",
    "df_x_onehot = pd.get_dummies(df_x_onehot)\n",
    "df_x_noText = df_x_onehot.copy()\n",
    "df_x_Text = df_x_onehot.copy()\n",
    "text_df = pd.read_csv(\"text_results_cleaned.csv\")\n",
    "df_x_Text['compound_tag_vader'] = text_df['compound_tag_vader']\n",
    "df_x_Text['pos_tag_disBert'] = text_df['pos_tag_disBert']\n",
    "df_x_Text['compound_ti_vader'] = text_df['compound_ti_vader']\n",
    "df_x_Text['pos_ti_disBert'] = text_df['pos_ti_disBert']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06555d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting data\n",
    "x_train_noText, x_test_noText, y_train_noText, y_test_noText = train_test_split(df_x_noText, df_y,\n",
    "                                                                             test_size=0.2, stratify=df_y['state'],\n",
    "                                                                             random_state=42)\n",
    "x_train_Text, x_test_Text, y_train_Text, y_test_Text = train_test_split(df_x_Text, df_y,\n",
    "                                                                             test_size=0.2, stratify=df_y['state'],\n",
    "                                                                             random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bbeb57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting into logistic regression model (no Text)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_clf_noText = LogisticRegression()\n",
    "log_clf_noText.fit(x_train_noText, y_train_noText['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4caee5a7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# compare to calibration curve\n",
    "from sklearn.calibration import calibration_curve\n",
    "y_train_predict_proba_logNoText = log_clf_noText.predict_proba(x_train_noText)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train_noText['state'], y_train_predict_proba_logNoText, n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, 's-',label='model performance')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray',label='Perfectly Caliberated')\n",
    "plt.xlabel(\"mean predicted value\")\n",
    "plt.ylabel(\"fraction of positives\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66309dd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending results into new dataFrame\n",
    "df_prob = pd.DataFrame()\n",
    "df_prob['log_prob_noText'] = y_train_predict_proba_logNoText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507f626",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting into logistic regression model (Text)\n",
    "log_clf_Text = LogisticRegression()\n",
    "log_clf_Text.fit(x_train_Text,y_train_Text['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f21d445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to calibration curve\n",
    "y_train_predict_proba_logText = log_clf_Text.predict_proba(x_train_Text)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train_Text['state'], y_train_predict_proba_logText, n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, 's-',label='model performance')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray',label='Perfectly Caliberated')\n",
    "plt.xlabel(\"mean predicted value\")\n",
    "plt.ylabel(\"fraction of positives\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a1eb14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending results into new dataFrame\n",
    "df_prob['log_prob_Text'] = y_train_predict_proba_logText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016105b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting into Tuned SVC (Text)\n",
    "from sklearn.svm import SVC\n",
    "support_clf = SVC(C= 0.1, gamma= 1, kernel= 'rbf',probability=True)\n",
    "support_clf.fit(x_train_Text,y_train_Text['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca82207e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to calibration curve\n",
    "y_train_predict_proba_SVC = support_clf.predict_proba(x_train_Text)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train_Text['state'], y_train_predict_proba_SVC, n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, 's-',label='model performance')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray',label='Perfectly Caliberated')\n",
    "plt.xlabel(\"mean predicted value\")\n",
    "plt.ylabel(\"fraction of positives\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06a54989",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending results into new dataFrame\n",
    "df_prob['SVC_Tuned_prob'] = y_train_predict_proba_SVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e19f931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting into Tuned XGB Classifier (No Text)\n",
    "from xgboost import XGBClassifier\n",
    "xgb_clf = XGBClassifier(seed=0,\n",
    "                       colsample_bytree= 0.5,\n",
    "                       gamma= 0.1, \n",
    "                       learning_rate= 0.0001,\n",
    "                       max_depth= 12,\n",
    "                       reg_alpha= 1e-05, \n",
    "                       reg_lambda= 1e-05)\n",
    "\n",
    "xgb_clf.fit(x_train_noText,y_train_noText['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384ac0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to calibration curve\n",
    "y_train_predict_proba_XGB_Tuned = xgb_clf.predict_proba(x_train_noText)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train_noText['state'], y_train_predict_proba_XGB_Tuned, n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, 's-',label='model performance')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray',label='Perfectly Caliberated')\n",
    "plt.xlabel(\"mean predicted value\")\n",
    "plt.ylabel(\"fraction of positives\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bd734f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending results into new dataFrame\n",
    "df_prob['xgboost_Tuned_prob'] = y_train_predict_proba_Tuned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1000cbd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitting into default XGB Classifier (No Text)\n",
    "xgb_clf = XGBClassifier(seed=0)\n",
    "xgb_clf.fit(x_train_noText,y_train_noText['state'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c7ae605",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compare to calibration curve\n",
    "y_train_predict_proba = xgb_clf.predict_proba(x_train_noText)[:, 1]\n",
    "fraction_of_positives, mean_predicted_value = calibration_curve(y_train_noText['state'], y_train_predict_proba, n_bins=10)\n",
    "plt.plot(mean_predicted_value, fraction_of_positives, 's-',label='model performance')\n",
    "plt.plot([0, 1], [0, 1], '--', color='gray',label='Perfectly Caliberated')\n",
    "plt.xlabel(\"mean predicted value\")\n",
    "plt.ylabel(\"fraction of positives\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2b6d8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# appending results into new dataFrame\n",
    "df_prob['xgboost_default_prob_noText'] = y_train_predict_proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545fb25",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d2c80e4c",
   "metadata": {},
   "source": [
    "We see that out of all the models, the default xgboost classifier has the smallest deviation with a perfectly caliberated model. We will use the results as our predictor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cee4d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_prob['amount_raised_usd_boxcox'] = y_train_noText['amount_raised_usd_boxcox']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8c8d852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import kendalltau\n",
    "from scipy.stats import spearmanr\n",
    "def pearson_corr(x,y,data):\n",
    "    corr = data.corr()[y][x]\n",
    "    print('Pearson correlation: %.5f' % corr)\n",
    "    \n",
    "def kendall_rank_corr(x,y,data):\n",
    "    corr, _ = kendalltau(data[x], data[y])\n",
    "    print('Kendall Rank correlation: %.5f' % corr)\n",
    "def spearman_corr(x,y,data):\n",
    "    rho, _ = spearmanr(data[x], data[y])\n",
    "    print('Spearman\\'s Correlation: %.5f' % rho)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a0ed35",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearson_corr('xgboost_default_prob','amount_raised_usd_boxcox',df_prob)\n",
    "kendall_rank_corr('xgboost_default_prob','amount_raised_usd_boxcox',df_prob)\n",
    "spearman_corr('xgboost_default_prob','amount_raised_usd_boxcox',df_prob)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37171987",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9dfa22d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "\n",
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(x_train_Text,y_train_Text)\n",
    "pred = xgb_reg.predict(x_test_Text)\n",
    "MSE = mean_squared_error(y_test_Text,pred)\n",
    "MAE = mean_absolute_error(y_test_Text,pred)\n",
    "r2 = r2_score(y_test_Text,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb53375b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE =\", MSE)\n",
    "print(\"MAE =\",MAE)\n",
    "print(\"Explained Variance =\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558e4aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_reg = XGBRegressor()\n",
    "xgb_reg.fit(x_train_noText,y_train_noText)\n",
    "pred = xgb_reg.predict(x_test_noText)\n",
    "MSE = mean_squared_error(y_test_noText,pred)\n",
    "MAE = mean_absolute_error(y_test_noText,pred)\n",
    "r2 = r2_score(y_test_noText,pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99691ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"MSE =\", MSE)\n",
    "print(\"MAE =\",MAE)\n",
    "print(\"Explained Variance =\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def0c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Text_reg = x_train_Text.reset_index()\n",
    "x_train_Text_reg = x_train_Text_reg.join(df_prob['xgboost_default_prob'])\n",
    "x_train_Text_reg.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f12a00e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_Text_reg = x_train_Text_reg.drop(['index'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc54ce85",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_Text_reg = y_train_Text.reset_index()\n",
    "y_train_Text_reg = y_train_Text_reg.drop(['index','state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1648b9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_Text_reg = x_test_Text.reset_index()\n",
    "x_test_Text_reg = x_test_Text_reg.drop(['index'],axis=1)\n",
    "xgb_clf = XGBClassifier(seed=0)\n",
    "xgb_clf.fit(x_train_Text,y_train_Text)\n",
    "x_test_Text_reg['xgboost_default_prob'] = xgb_clf(seed=0).predict_proba(x_test_Text)[:, 1]\n",
    "y_test_Text_reg = y_test_Text.reset_index()\n",
    "y_test_Text_reg = y_test_Text_reg.drop(['index','state'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47994d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = xgb_reg.predict(x_test_Text_reg)\n",
    "MSE = mean_squared_error(y_test_Text_reg,pred)\n",
    "MAE = mean_absolute_error(y_test_Text_reg,pred)\n",
    "r2 = r2_score(y_test_Text_reg,pred)\n",
    "\n",
    "print(\"MSE =\", MSE)\n",
    "print(\"MAE =\",MAE)\n",
    "print(\"Explained Variance =\",r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a78261f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_Text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a682b2ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
